{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing things in the notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import sys\n",
    "%matplotlib inline\n",
    "sys.version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the necessary Libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyworkout.parsers import tcxtools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How bad does one of the TCX files look? The data cleaning will be done by the framework, but look how bad it is in raw form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "workout_data = tcxtools.TCXPandas('raw_data/activity_248017020.tcx') # Create the Class Object\n",
    "workout_data_dd = workout_data.parse()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore and visualize some of the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Free form here: play with pandas a bit to see what is possible.  Note that you can actually instantiate pandas graphing using matplotlib here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "workout_data_dd.plot.scatter('cadence','power')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Playing with Bokeh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bokeh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bokeh.plotting import figure, output_file, show\n",
    "from bokeh.io import output_notebook\n",
    "output_notebook()\n",
    "\n",
    "p = figure(title=\"Exploring power vs distance\", x_axis_label='x', y_axis_label='y')\n",
    "p.line(workout_data_dd.distance, workout_data_dd.power, legend=\"Power (Watts)\", line_width=2)\n",
    "\n",
    "# show the results\n",
    "show(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_notebook()\n",
    "p = figure(title=\"Exploring power vs cadence\", x_axis_label='x', y_axis_label='y')\n",
    "p.scatter(workout_data_dd.power, workout_data_dd.cadence)\n",
    "\n",
    "# show the results\n",
    "show(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scikit-learn: some quick fun testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the basic model necessities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection\n",
    "from sklearn import linear_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parse the dataset, then add in model_selection's train/test split\n",
    "before training the model, drop the following features: time, power, latitude, longitude"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are trying to calculate the power (target) based on the other features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = workout_data.parse()\n",
    "# Reduce the dataset\n",
    "red_dataset = dataset.drop(['time','power','latitude','longitude'], axis=1)\n",
    "X_train, X_test, y_train, y_test = # TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regression_model = linear_model.LinearRegression()\n",
    "# TODO: Train your model\n",
    "mse = np.mean((regression_model.predict(X_test) - y_test) ** 2)\n",
    "score = regression_model.score(X_test, y_test)\n",
    "print(regression_model.coef_, mse, score, regression_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_values = regression_model.predict(dataset.drop(['time','power','latitude','longitude'], axis=1))\n",
    "plt.plot(dataset.distance[5000:6000], dataset.power[5000:6000], c='red')\n",
    "plt.plot(dataset.distance[5000:6000], pred_values[5000:6000])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "red_dataset.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Scaling out via Dask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "One of the neat things of dask is when you need general analysis in concurrent flows to be accomplished\n",
    "What is the code doing below?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.dataframe as dd\n",
    "from distributed import client\n",
    "from dask import delayed\n",
    "tcx_list = glob.glob(\"raw_data/*.tcx\")\n",
    "list_of_delayed = []\n",
    "for files in tcx_list:\n",
    "    list_of_delayed.append(delayed(tcxtools.TCXPandas(files).parse()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_delayed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total = dd.from_delayed(list_of_delayed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the same analysis of ML as before, but now with this dask dataframe delayed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python IDP3.6",
   "language": "python",
   "name": "idp36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
